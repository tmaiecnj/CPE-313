{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz2nMmsLAAfutqKyLwKqvP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmaiecnj/CPE-313/blob/main/Hands-on%20Activity%207.1%20-%20Deep%20Learning%20in%20Time%20Series.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Github Link: [Hands-on Activity 7.1: Deep Learning in Time Series]()"
      ],
      "metadata": {
        "id": "B5YG4P0IO75_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Activity 4.4 Deep Learning in Time Series"
      ],
      "metadata": {
        "id": "p5ztWxyfPOXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objective(s):\n",
        "This activity aims to introduce how to build and train a simple RNN or LSTM for time series forecasting, using Keras."
      ],
      "metadata": {
        "id": "b6_8HymXPRuf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intended Learning Outcomes (ILOs):\n",
        "* Demonstrate how to build and train RNN for time series forecasting\n",
        "* Demonstrate how to build and train LSTM for time series forecasting"
      ],
      "metadata": {
        "id": "eMyQ3CdRPRr0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resources:\n",
        "* Jupyter Notebook\n",
        "* Beijing.csv"
      ],
      "metadata": {
        "id": "OBAL_oYEPRof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procedures"
      ],
      "metadata": {
        "id": "Q4cIsQMZPy8E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the necessary libraries"
      ],
      "metadata": {
        "id": "8uOzRjQmP4F1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_UiLIvwO65-"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('fivethirtyeight')\n",
        "import pandas as pd\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, SimpleRNN, LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a recurrent neural network and train it to forecast a single time series.\n",
        "* Load and setup the dataset"
      ],
      "metadata": {
        "id": "QfWIPcDPQGmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Beijing = pd.read_csv('Beijing.csv')\n",
        "df_Beijing = df_Beijing[df_Beijing.year >= 2015]\n",
        "df_Beijing.head(10)"
      ],
      "metadata": {
        "id": "rixJ5NleQGdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forecast the 'PM' series, which are measurements of air pollution for several different districts. Note that there are occasional missing values in these series, which we can fill with simple linear interpolation. To start, we'll focus on the \"PM_Dongsi\" series and interpolate the missing values."
      ],
      "metadata": {
        "id": "iuPGmY45QO3T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_Beijing['PM_Dongsi'] = df_Beijing['PM_Dongsi'].interpolate()\n",
        "df_Beijing['PM_Dongsi'].head(10)"
      ],
      "metadata": {
        "id": "G1-UHhvTQNOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a function to extract and plot the last *n* days of data"
      ],
      "metadata": {
        "id": "Tp724fxbQW6P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_n_last_days(df, series_name, n_days):\n",
        "  \"\"\"\n",
        "  Extract last n_days of an hourly time series\n",
        "  \"\"\"\n",
        "    return df[series_name][-(24*n_days):]"
      ],
      "metadata": {
        "id": "52tZN6iqQcHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_n_last_days(df, series_name, n_days):\n",
        "  \"\"\"\n",
        "  Plot last n_days of an hourly time series\n",
        "  \"\"\"\n",
        "  plt.plot(get_n_last_days(df, series_name, n_days), 'k-')\n",
        "  plt.title('{0} Air Quality Time Series - {1} days'.format(series_name, n_days))\n",
        "\n",
        "  plt.xlabel('Recorded Hour')\n",
        "  plt.ylabel('Reading')\n",
        "  plt.grid(alpha=0.3)"
      ],
      "metadata": {
        "id": "Cw_dMF-IQjZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check last 6 weeks of data look like"
      ],
      "metadata": {
        "id": "UpsqQqo-Q1JP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_n_last_days(df_Beijing, 'PM_Dongsi', 42)"
      ],
      "metadata": {
        "id": "aVaUmMvaQ2q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a simple RNN to forecast the PM_Dongsi time series"
      ],
      "metadata": {
        "id": "qOo0Z02sQ49r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_keras_format_series(series):\n",
        "  \"\"\"\n",
        "  Convert a series to a numpy array of shape\n",
        "  [n_samples, time_steps, features]\n",
        "  \"\"\"\n",
        "\n",
        "  series = np.array(series)\n",
        "  return series.reshape(series.shape[0], series.shape[1], 1)"
      ],
      "metadata": {
        "id": "_-30beCLQ37r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_test_data(df, series_name, series_days, input_hours, test_hours, sample_gap=3):\n",
        "  \"\"\"\n",
        "  Utility processing function that splits an hourly time series into\n",
        "  train and test with keras-friendly format, according to user-specified\n",
        "  choice of shape.\n",
        "\n",
        "  arguments\n",
        "  ---------\n",
        "  df (dataframe): dataframe with time series columns\n",
        "  series_name (string): column name in df\n",
        "  series_days (int): total days to extract\n",
        "  input_hours (int): length of sequence input to network\n",
        "  test_hours (int): length of held-out terminal sequence\n",
        "  sample_gap (int): step size between start of train sequences; default 5\n",
        "\n",
        "  returns\n",
        "  ---------\n",
        "  tuple: train_X, test_X_init, train_y, test_y\n",
        "  \"\"\"\n",
        "\n",
        "  forecast_series = get_n_last_days(df, series_name, series_days).values\n",
        "\n",
        "  train = forecast_series[:-test_hours]\n",
        "  test = forecast_series[-test_hours:]\n",
        "\n",
        "  train_X, train_y = [], []\n",
        "\n",
        "  for i in range(0, train.shape[0]-input_hours, sample_gap):\n",
        "    train_X.append(train[i:i+input_hours])\n",
        "    train_y.append(train[i+input_hours])\n",
        "\n",
        "  train_X = get_keras_format_series(train_X)\n",
        "  train_y = np.array(train_y)\n",
        "\n",
        "  test_X_init = test[:input_hours]\n",
        "  test_y = test[input_hours:]\n",
        "\n",
        "  return train_X, test_X_init, train_y, test_y"
      ],
      "metadata": {
        "id": "XuZW_twdRC6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the get_train_test_data utility function in hand, we're all set to extract keras-friendly arrays and\n",
        "start training simple RNN models. We run this function in the cell below. We use the last 56 days of\n",
        "the PM_Dongsi series, and will train a model that takes in 12 time steps in order to predict the next\n",
        "time step. We use the last day of data for visually testing the model."
      ],
      "metadata": {
        "id": "cyPFVLmSRuMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series_days = 56\n",
        "input_hours = 12\n",
        "test_hours = 24"
      ],
      "metadata": {
        "id": "m8w0QqfFRx0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X_init, train_y, test_y = (get_train_test_data(df_Beijing,\n",
        "                                                             'PM_Dongsi',\n",
        "                                                             series_days,\n",
        "                                                             input_hours,\n",
        "                                                             test_hours))"
      ],
      "metadata": {
        "id": "E6YmgswbR0Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below we see that by taking multiple time slices, we get 436 training samples of 12 time steps each."
      ],
      "metadata": {
        "id": "8i9o_G84R7lG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Training shape: {}'.format(train_X.shape))"
      ],
      "metadata": {
        "id": "f4zTZ8b5R-EW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a simple RNN model using keras."
      ],
      "metadata": {
        "id": "4f2bwvjeSAZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_SimpleRNN(train_X, train_y, cell_units, epochs):\n",
        "  \"\"\"\n",
        "  Fit Simple RNN to data train_X, train_y\n",
        "\n",
        "  arguments\n",
        "  ---------\n",
        "  train_X (array): input sequence samples for training\n",
        "  train_y (list): next step in sequence targets\n",
        "  cell_units (int): number of hidden units for RNN cells\n",
        "  epochs (int): number of training epochs\n",
        "  \"\"\"\n",
        "\n",
        "  # initialize model\n",
        "  model = Sequential()\n",
        "\n",
        "  # construct an RNN layer with specified number of hidden units\n",
        "  # per cell and desired sequence input format\n",
        "  model.add(SimpleRNN(cell_units, input_shape=(train_X.shape[1],1)))\n",
        "\n",
        "  # add an output layer to make final predictions\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  # define the loss function / optimization strategy, and fit\n",
        "  # the model with the desired number of passes over the data (epochs)\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  model.fit(train_X, train_y, epochs=epochs, batch_size=64, verbose=0)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "vaCvVrRHSABy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this function to fit a very simple baseline model."
      ],
      "metadata": {
        "id": "RdfZD5MwSOMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = fit_SimpleRNN(train_X, train_y, cell_units=10, epochs=10)"
      ],
      "metadata": {
        "id": "WrlblNlrR_IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This prediction method and a utility function for plotting its output against the ground truth are\n",
        "defined below."
      ],
      "metadata": {
        "id": "nisPsXOnSRrB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X_init, n_steps, model):\n",
        "  \"\"\"\n",
        "  Given an input series matching the model's expected format,\n",
        "  generates model's predictions for next n_steps in the series\n",
        "  \"\"\"\n",
        "\n",
        "  X_init = X_init.copy().reshape(1,-1,1)\n",
        "  preds = []\n",
        "\n",
        "  # iteratively take current input sequence, generate next step pred,\n",
        "  # and shift input sequence forward by a step (to end with latest pred).\n",
        "  # collect preds as we go.\n",
        "  for _ in range(n_steps):\n",
        "    pred = model.predict(X_init)\n",
        "    preds.append(pred)\n",
        "    X_init[:,:-1,:] = X_init[:,1:,:]\n",
        "    X_init[:,-1,:] = pred\n",
        "\n",
        "  preds = np.array(preds).reshape(-1,1)\n",
        "  return preds"
      ],
      "metadata": {
        "id": "MuZkfsgLSQYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_and_plot(X_init, y, model, title):\n",
        "  \"\"\"\n",
        "  Given an input series matching the model's expected format,\n",
        "  generates model's predictions for next n_steps in the series,\n",
        "  and plots these predictions against the ground truth for those steps\n",
        "\n",
        "  arguments\n",
        "  ---------\n",
        "  X_init (array): initial sequence, must match model's input shape\n",
        "  y (array): true sequence values to predict, follow X_init\n",
        "  model (keras.models.Sequential): trained neural network\n",
        "  title (string): plot title\n",
        "  \"\"\"\n",
        "\n",
        "  y_preds = predict(test_X_init, n_steps=len(y), model=model)\n",
        "\n",
        "  start_range = range(1, input_hours+1)\n",
        "  predict_range = range(input_hours, test_hours)\n",
        "\n",
        "  plt.plot(start_range, test_X_init)\n",
        "  plt.plot(predict_range, test_y, color='orange')\n",
        "  plt.plot(predict_range, y_preds, color='teal', linestyle='--')\n",
        "\n",
        "  plt.title(title)\n",
        "  plt.legend(['Initial Series','Target Series','Predictions'])"
      ],
      "metadata": {
        "id": "zd-hpX95Sb2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_plot(test_X_init,\n",
        "                 test_y, model,\n",
        "                 'PM Series: Test Data and Simple RNN Predictions')"
      ],
      "metadata": {
        "id": "lsTdb55HSpup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrain the model a few times in order to get results that we're happy with."
      ],
      "metadata": {
        "id": "A-OkKjcFSuxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = fit_SimpleRNN(train_X, train_y, cell_units=30, epochs=1200)"
      ],
      "metadata": {
        "id": "3YzBFbW8SwV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_plot(test_X_init,\n",
        "                 test_y, model,\n",
        "                 'PM Series: Test Data and Simple RNN Predictions')"
      ],
      "metadata": {
        "id": "3ZgVRmMyS2LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "Ndd0xjueS287"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "uHhcZ7aeS8UM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a new function for fitting an LSTM with keras"
      ],
      "metadata": {
        "id": "sDY0OD9zS-P2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_LSTM(train_X, train_y, cell_units, epochs):\n",
        "  \"\"\"\n",
        "  Fit LSTM to data train_X, train_y\n",
        "\n",
        "  arguments\n",
        "  ---------\n",
        "  train_X (array): input sequence samples for training\n",
        "  train_y (list): next step in sequence targets\n",
        "  cell_units (int): number of hidden units for LSTM cells\n",
        "  epochs (int): number of training epochs\n",
        "  \"\"\"\n",
        "\n",
        "  # initialize model\n",
        "  model = Sequential()\n",
        "\n",
        "  # construct a LSTM layer with specified number of hidden units\n",
        "  # per cell and desired sequence input format\n",
        "  model.add(LSTM(cell_units, input_shape=(train_X.shape[1],1)))\n",
        "\n",
        "  # add an output layer to make final predictions\n",
        "  model.add(Dense(1))\n",
        "\n",
        "  # define the loss function / optimization strategy, and fit\n",
        "  # the model with the desired number of passes over the data (epochs)\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "  model.fit(train_X, train_y, epochs=epochs, batch_size=64, verbose=0)\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Q7zQUnOPS_r0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train a LSTM to forecast the PM_Nongzhanguan time series"
      ],
      "metadata": {
        "id": "V-3JY8_7TK3J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series_days = 50\n",
        "input_hours = 12\n",
        "test_hours = 96"
      ],
      "metadata": {
        "id": "iQvntG8OTM0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X, test_X_init, train_y, test_y = (get_train_test_data(df_Beijing,\n",
        "                                                             'PM_Nongzhanguan',\n",
        "                                                             series_days,\n",
        "                                                             input_hours,\n",
        "                                                             test_hours))"
      ],
      "metadata": {
        "id": "ulQBwaKmTOdl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = fit_LSTM(train_X, train_y, cell_units=70, epochs=3000)"
      ],
      "metadata": {
        "id": "ODyoRlh2TZGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict_and_plot(test_X_init,\n",
        "                 test_y, model,\n",
        "                 'PM_Nongzhanguan Series: Test Data and LSTM Predictions')"
      ],
      "metadata": {
        "id": "TWk83oO9TaVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "g4hWyG9RTcoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Supplementary Activity"
      ],
      "metadata": {
        "id": "MxFZBNJBTedu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Train your own model to forecast the \"PM_Nongzhanguan\" series from the Beijing dataframe.\n",
        "* Train a LSTM to forecast the PM_Dongsi time series"
      ],
      "metadata": {
        "id": "wd7WH7LeThHA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "1OtIOm9nTlgQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Conclusion*"
      ],
      "metadata": {
        "id": "F4UcNHpeTpCi"
      }
    }
  ]
}